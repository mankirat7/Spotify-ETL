{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f0c3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import base64\n",
    "import webbrowser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20f945f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client_id = \"a6eea1959e344ead823106e86277724e\"\n",
    "client_secret = \"479f3fabe040437eb3c4be2e7c472bad\"\n",
    "\n",
    "auth_headers = {\n",
    "    \"client_id\": client_id,\n",
    "    \"response_type\": \"code\",\n",
    "    \"redirect_uri\": \"http://localhost:7777/callback\",\n",
    "    \"scope\": \"user-read-recently-played\"\n",
    "}\n",
    "\n",
    "webbrowser.open(\"https://accounts.spotify.com/authorize?\" + urlencode(auth_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53941bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"AQCLXqbkTCZnBwY5Z5wnU0-dJMFWW0cwUja1vE-L6OTYhFEL11DWszN-ZAoqCtgKUpgopGy1s_1o-Arr-yCOQunoBxlFF8mvghqJEGULgfSCEHe7o9hvGnHMWdefDITqBhZrSt9U0FvVFuCfhM-MySghsXxne_gGlRrIKwG7ErWoEhz0pJZUum2s6mLTuIs-4gAhz1_ffC275BXMmQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f67e435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_credentials = base64.b64encode(client_id.encode() + b':' + client_secret.encode()).decode(\"utf-8\")\n",
    "\n",
    "token_headers = {\n",
    "    \"Authorization\": \"Basic \" + encoded_credentials,\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "\n",
    "token_data = {\n",
    "    \"grant_type\": \"authorization_code\",\n",
    "    \"code\": code,\n",
    "    \"redirect_uri\": \"http://localhost:7777/callback\"\n",
    "}\n",
    "\n",
    "r = requests.post(\"https://accounts.spotify.com/api/token\", data=token_data, headers=token_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9277515d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cc4302d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQDFoEoc5tVbyHS6BIWg-llFNg0B8LjrrMA92VFo1StOxCSNFlZLG-DZcTlAXZ2ZsWr9Fy5o7imwpE1MDp4nUOOJCQYn4enpH-zi2oDcJPMGeQzFYgI52ycJowCycntgWPPh8wVkj8ImMa_uSJ9sRPgIPZuaA7X40VsqNe-xmjhLWiihtuNQP0NBx__ZsrLkcZRC0E6Qxzc\n"
     ]
    }
   ],
   "source": [
    "token = r.json()[\"access_token\"]\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3cbbf1",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1145c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "\n",
    "\n",
    "USER_ID = \"Mankirat\"\n",
    "TOKEN = token\n",
    "\n",
    "\n",
    "# Creating an function to be used in other pyrhon files\n",
    "def return_dataframe(): \n",
    "    input_variables = {\n",
    "        \"Accept\" : \"application/json\",\n",
    "        \"Content-Type\" : \"application/json\",\n",
    "        \"Authorization\" : \"Bearer {token}\".format(token=TOKEN)\n",
    "    }\n",
    "     \n",
    "    today = datetime.datetime.now()\n",
    "    yesterday = today - datetime.timedelta(days=2)\n",
    "    yesterday_unix_timestamp = int(yesterday.timestamp()) * 1000\n",
    "\n",
    "    # Download all songs you've listened to \"after yesterday\", which means in the last 24 hours      \n",
    "    r = requests.get(\"https://api.spotify.com/v1/me/player/recently-played?after={time}\".format(time=yesterday_unix_timestamp), headers = input_variables)\n",
    "\n",
    "    data = r.json()\n",
    "    song_names = []\n",
    "    artist_names = []\n",
    "    played_at_list = []\n",
    "    timestamps = []\n",
    "    \n",
    "\n",
    "    # Extracting only the relevant bits of data from the json object      \n",
    "    for song in data[\"items\"]:\n",
    "        song_names.append(song[\"track\"][\"name\"])\n",
    "        artist_names.append(song[\"track\"][\"album\"][\"artists\"][0][\"name\"])\n",
    "        played_at_list.append(song[\"played_at\"])\n",
    "        timestamps.append(song[\"played_at\"][0:10])\n",
    "        \n",
    "    # Prepare a dictionary in order to turn it into a pandas dataframe below       \n",
    "    song_dict = {\n",
    "        \"song_name\" : song_names,\n",
    "        \"artist_name\": artist_names,\n",
    "        \"played_at\" : played_at_list,\n",
    "        \"timestamp\" : timestamps\n",
    "    }\n",
    "    song_df = pd.DataFrame(song_dict, columns = [\"song_name\", \"artist_name\", \"played_at\", \"timestamp\"])\n",
    "    return song_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e3915",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d23a52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ID   timestamp    artist_name  count\n",
      "0          2023-07-14-DIVINE  2023-07-14         DIVINE      1\n",
      "1     2023-07-14-Don Toliver  2023-07-14    Don Toliver      1\n",
      "2      2023-07-14-Elley Duhé  2023-07-14     Elley Duhé      1\n",
      "3           2023-07-14-Fateh  2023-07-14          Fateh      3\n",
      "4           2023-07-14-Gunna  2023-07-14          Gunna      2\n",
      "5            2023-07-14-Jaan  2023-07-14           Jaan      2\n",
      "6           2023-07-14-Lithe  2023-07-14          Lithe      1\n",
      "7        2023-07-14-Mr.Dhatt  2023-07-14       Mr.Dhatt      1\n",
      "8   2023-07-14-Nipsey Hussle  2023-07-14  Nipsey Hussle      2\n",
      "9      2023-07-14-The Weeknd  2023-07-14     The Weeknd      1\n",
      "10      2023-07-14-Tom Odell  2023-07-14      Tom Odell      1\n",
      "11        2023-07-14-Tympana  2023-07-14        Tympana      1\n",
      "12    2023-07-14-Wazir Patar  2023-07-14    Wazir Patar      1\n",
      "13   2023-07-14-XXXTENTACION  2023-07-14   XXXTENTACION      1\n",
      "14       2023-07-14-omgkirby  2023-07-14       omgkirby      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Set of Data Quality Checks Needed to Perform Before Loading\n",
    "def Data_Quality(load_df):\n",
    "    #Checking Whether the DataFrame is empty\n",
    "    if load_df.empty:\n",
    "        print('No Songs Extracted')\n",
    "        return False\n",
    "    \n",
    "    #Enforcing Primary keys since we don't need duplicates\n",
    "    if pd.Series(load_df['played_at']).is_unique:\n",
    "       pass\n",
    "    else:\n",
    "        #The Reason for using exception is to immediately terminate the program and avoid further processing\n",
    "        raise Exception(\"Primary Key Exception,Data Might Contain duplicates\")\n",
    "    \n",
    "    #Checking for Nulls in our data frame \n",
    "    if load_df.isnull().values.any():\n",
    "        raise Exception(\"Null values found\")\n",
    "\n",
    "# Writing some Transformation Queries to get the count of artist\n",
    "def Transform_df(load_df):\n",
    "\n",
    "    #Applying transformation logic\n",
    "    Transformed_df=load_df.groupby(['timestamp','artist_name'],as_index = False).count()\n",
    "    Transformed_df.rename(columns ={'played_at':'count'}, inplace=True)\n",
    "\n",
    "    #Creating a Primary Key based on Timestamp and artist name\n",
    "    Transformed_df[\"ID\"] = Transformed_df['timestamp'].astype(str) +\"-\"+ Transformed_df[\"artist_name\"]\n",
    "\n",
    "    return Transformed_df[['ID','timestamp','artist_name','count']]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Importing the songs_df from the Extract.py\n",
    "    load_df=return_dataframe()\n",
    "    Data_Quality(load_df)\n",
    "    #calling the transformation\n",
    "    Transformed_df=Transform_df(load_df)    \n",
    "    print(Transformed_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca935c3b",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1b69831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n",
      "Data already exists in the database\n",
      "Data already exists in the database2\n",
      "Close database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd \n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "DATABASE_LOCATION = \"sqlite:///my_played_tracks.sqlite\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#Importing the songs_df from the Extract.py\n",
    "    load_df=return_dataframe()\n",
    "    if(Data_Quality(load_df) == False):\n",
    "        raise (\"Failed at Data Validation\")\n",
    "    Transformed_df=Transform_df(load_df)\n",
    "    #The Two Data Frame that need to be Loaded in to the DataBase\n",
    "\n",
    "#Loading into Database\n",
    "    engine = sqlalchemy.create_engine(DATABASE_LOCATION)\n",
    "    conn = sqlite3.connect('my_played_tracks.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    #SQL Query to Create Played Songs\n",
    "    sql_query_1 = '''\n",
    "    CREATE TABLE IF NOT EXISTS my_played_tracks(\n",
    "        song_name VARCHAR(200),\n",
    "        artist_name VARCHAR(200),\n",
    "        played_at VARCHAR(200),\n",
    "        timestamp VARCHAR(200),\n",
    "        CONSTRAINT primary_key_constraint PRIMARY KEY (played_at)\n",
    "    )\n",
    "    '''\n",
    "    #SQL Query to Create Most Listened Artist\n",
    "    sql_query_2 = '''\n",
    "    CREATE TABLE IF NOT EXISTS fav_artist(\n",
    "        timestamp VARCHAR(200),\n",
    "        ID VARCHAR(200),\n",
    "        artist_name VARCHAR(200),\n",
    "        count VARCHAR(200),\n",
    "        CONSTRAINT primary_key_constraint PRIMARY KEY (ID)\n",
    "    )\n",
    "    '''\n",
    "    cursor.execute(sql_query_1)\n",
    "    cursor.execute(sql_query_2)\n",
    "    print(\"Opened database successfully\")\n",
    "\n",
    "    #We need to only Append New Data to avoid duplicates\n",
    "    try:\n",
    "        load_df.to_sql(\"my_played_tracks\", engine, index=False, if_exists='append')\n",
    "    except:\n",
    "        print(\"Data already exists in the database\")\n",
    "    try:\n",
    "        Transformed_df.to_sql(\"fav_artist\", engine, index=False, if_exists='append')\n",
    "    except:\n",
    "        print(\"Data already exists in the database2\")\n",
    "\n",
    "    #cursor.execute('DROP TABLE my_played_tracks')\n",
    "    #cursor.execute('DROP TABLE fav_artist')\n",
    "\n",
    "    conn.close()\n",
    "    print(\"Close database successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
